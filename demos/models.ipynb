{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`soupsavvy` provides a streamlined approach to object-oriented web scraping through user-defined models. These models allow you to locate and extract specific structures within HTML content. Each model represents an object expected to be found within a defined scope element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations are objects designed to encapsulate transformation logic, such as extracting text from an element, converting data types, or applying custom transformations. You can apply operations after a selector and chain them as needed using the pipe `|` operator. For example, to extract and format the price of a book from a specific HTML structure, you might chain operations to extract text (`Text`), remove a currency symbol (using a custom `Operation`), and convert the value to float (`Operation`).\n",
    "\n",
    "The `Operation` component allows for any user-defined transformation. It takes a callable that accepts a single argument, performs the transformation, and returns the modified value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soupsavvy.operations import Operation\n",
    "\n",
    "operation = Operation(lambda x: x.strip(\"$\"))\n",
    "operation.execute(\"100$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All `soupsavvy` operations are mixins of searcher and operation, it can be used both as operation (`execute` method) and as a searcher (`find`, `find_all` methods), which calls the `execute` method internally. They can be used as fields of model to extract data directly from scope element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy.operations import Operation\n",
    "\n",
    "text = \"\"\"\n",
    "    <p class=\"title\" id=\"book1\">Animal Farm</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"html.parser\")\n",
    "\n",
    "operation = Operation(lambda x: x.get(\"id\"))\n",
    "operation.find(soup.p)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soupsavvy.operations import Operation\n",
    "\n",
    "operation = (\n",
    "    Operation(lambda x: x.strip(\"$\")) | Operation(int) | Operation(lambda x: x * 2)\n",
    ")\n",
    "operation.execute(\"100$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Text` is a built-in operation that extracts the text content of an element. It's very common and useful operation in web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy.operations import Text\n",
    "\n",
    "text = \"\"\"\n",
    "    <p class=\"title\">Animal Farm</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"html.parser\")\n",
    "operation = Text()\n",
    "operation.execute(soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Text` wraps the `get_text` method from BeautifulSoup, providing a familiar interface, operation accepts the following arguments:\n",
    "\n",
    "- **`strip` (bool):** Determines whether to remove leading and trailing whitespaces and newline characters from the extracted text. Defaults to `False`.\n",
    "- **`separator` (str):** Specifies a separator to join multiple text nodes within the element. Defaults to an empty string (`\"\"`), meaning no separator is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy.operations import Text\n",
    "\n",
    "text = \"\"\"\n",
    "    <p class=\"title\">  Animal Farm  \\n\\n</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "operation = Text(strip=True)\n",
    "operation.execute(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy.operations import Text\n",
    "\n",
    "text = \"\"\"\n",
    "    <div>\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "operation = Text(separator=\" -- \", strip=True)\n",
    "operation.execute(soup.div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Href` is a built-in operation that extracts value of `href` attribute from an element. It does not accepts any parameters. If `href` attribute is not found in the element, it returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy.operations import Href\n",
    "\n",
    "text = \"\"\"\n",
    "    <a href=\"www.book.com\">Animal Farm</a>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "operation = Href()\n",
    "operation.execute(soup.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Parent` is an operation that extracts the parent element of the current element. It can be used to navigate to a higher level in the HTML structure. It does not accepts any parameters. Unlike `Href` or `Text`, it is soup selector, as it returns a BeautifulSoup `Tag` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy.operations import Parent\n",
    "\n",
    "text = \"\"\"\n",
    "    <div><a href=\"www.book.com\">Animal Farm</a></div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "operation = Parent()\n",
    "operation.execute(soup.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Parent` operations can be chained together resulting in `OperationPipeline` object, as operation is higher in inheritance hierarchy than selector. Instance in example below will return the parent of the parent of the element when performing operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy.operations import Parent\n",
    "\n",
    "text = \"\"\"\n",
    "    <div><div><a href=\"www.book.com\">Animal Farm</a></div></div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "operation = Parent() | Parent()\n",
    "operation.execute(soup.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining with selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selector can be combined with operation to extract data from the selected element. Using `|` operator on selector and operation will create instance of `SelectionPipeline`, which first finds element with provided selector and applies operation on it subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100$</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "selector = ClassSelector(\"book\") > ClassSelector(\"price\")\n",
    "operation = Text() | Operation(lambda x: x.strip(\"$\")) | Operation(int)\n",
    "\n",
    "pipeline = selector | operation\n",
    "pipeline.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a user-defined model in `soupsavvy`, ensure that it meets the following requirements:\n",
    "\n",
    "- The class must inherit from `soupsavvy.models.BaseModel`.\n",
    "- It must include a `__scope__` class attribute that defines the model's scope.\n",
    "- The model should have at least one field defined as a class attribute.\n",
    "\n",
    "**Scope:** The scope defines the HTML element that is expected to contain all the fields of the model. This must be a `soupsavvy` selector. When an element matches the scope selector, the model is considered found, and its fields are extracted.\n",
    "\n",
    "**Field:** A field represents a specific piece of information expected to be found within the scope element. Fields are defined as class attributes, like `title` and `price` in the example below. Any attribute with a value that is an instance of `TagSearcher` is recognized as a model field. The value can be:\n",
    "\n",
    "- Selector, e.g.: `ClassSelector(\"book\")`\n",
    "- Selector-Operation pipeline, e.g.: `ClassSelector(\"price\") | Text() | Operation(int)`\n",
    "- Another model class that inherits from `BaseModel`, e.g.: `Author`\n",
    "- Mixin that functions as both a selector and an operation, e.g.: `Text()`, `Href()` or `Operation(lambda x: x.get(\"id\"))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To locate instances of a model within an HTML document, `find` method can be invoked on the model class. This method accepts a BeautifulSoup `Tag` object as an argument and returns the instance of the model found within the first found scope.\n",
    "\n",
    "In the example below, the `Book` class defines a model expected to be contained within a `div` element with the class `book`. The model includes two fields:\n",
    "\n",
    "- **`title`**: Extracts the text content from an element with the class `title`.\n",
    "- **`price`**: Extracts the text content from an element with the class `price` and converts it to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no scope is found in provided tag, `find` method returns `None` and model is not extracted by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"ebook\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "result = Book.find(soup)\n",
    "assert result is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using `strict` mode, when `find` method fails to find specified scope, `ModelNotFoundException` exception is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.exceptions import ModelNotFoundException\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"ebook\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "\n",
    "try:\n",
    "    Book.find(soup, strict=True)\n",
    "except ModelNotFoundException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "By default, if an error occurs during data extraction, it is propagated, preventing the model from being built. In the example below, if the `price` element is not found within the specified scope, the selector returns `None`. This causes the `Text` operation to fail, as it cannot extract text from `None`.\n",
    "\n",
    "It's important to note that the `strict` parameter applies only to the scope search, not to individual field selectors. Field selectors are *forgiving* - they proceed to the next operation even if the previous one returns `None`. As a result, any potential edge cases must be explicitly handled within the model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.exceptions import FieldExtractionException\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "\n",
    "try:\n",
    "    Book.find(soup)\n",
    "except FieldExtractionException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations as fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, operations can be used as fields in the model. They are used to extract and transform data from the scope element. In the example below, `Operation` is used to extract `id` attribute from the element and `Href` is used to extract `href` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Href\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\")\n",
    "\n",
    "    id = Operation(lambda x: x.get(\"id\"))\n",
    "    link = Href()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div id=\"book1\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrappers are higher-order components that modify the behavior of operations or selectors. They provide enhanced control over the extraction process, allowing you to handle edge cases more gracefully and build more complex models. By wrapping operations or selectors, you can customize how data is extracted, transformed, or handled when certain conditions are met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SkipNone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you anticipate that the `price` element might be absent from the scope, you can use the `SkipNone` operation wrapper. This wrapper ensures that subsequent operations, like extracting text or converting to an integer, are only performed if the `price` element is found. If the input is `None`, `SkipNone` simply returns `None` without applying the wrapped operation. As a result, if a field selector returns `None`, the corresponding field in the model instance is automatically set to `None`, since all fields are nullable by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel, SkipNone\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | SkipNone(Text() | Operation(int))\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to handle errors is by using the `Suppress` operation wrapper, which catches and suppresses any exceptions that occur during operation execution. When an exception is raised, `Suppress` returns `None`. This is particularly useful when you anticipate that the input might be incompatible with the operation. In the example below, while the `price` element is expected to be present, the text might be empty. By using `Suppress`, we handle the case where converting an empty string to an integer would normally raise an exception, ensuring the operation returns `None` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel, Suppress\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Suppress(Operation(int))\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\"></p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scenario can be handled more precisely using the `Default` field wrapper. When the field selector returns `None`, the default value is used. For instance, if an empty `price` element should be interpreted as a price of `0`, the `Default` operation can be employed to manage this case. It's important to note that while `Default` handles missing elements by substituting the default value, it will still propagate any exceptions that occur during extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel, Default, Suppress\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = Default(ClassSelector(\"price\") | Text() | Suppress(Operation(int)), 0)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">hundred</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Suppress` by default suppresses operation when it raised any exception, which is subclass of `Exception`. It allows to specify category of exceptions to suppress by passing `category` parameter.  \n",
    "\n",
    "It can be either:\n",
    "- **single exception class** ex. `category=ValueError`\n",
    "- **tuple of exception classes** ex. `category=(ValueError, TypeError)`\n",
    "\n",
    "to pass to `issubclass` function.  \n",
    "In example below, `ValueError` is raised when converting empty non-integer string to integer and it's suppressed by operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel, Default, Suppress\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = (\n",
    "        ClassSelector(\"price\") | Text() | Suppress(Operation(int), category=ValueError)\n",
    "    )\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">hundred</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any other then specified exception is not suppressed. In example below, only `TypeError` is handled by `Suppress` operation, while `ValueError`, which is raised by wrapped operation is propagated, as it's not `TypeError` or its subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.exceptions import FieldExtractionException\n",
    "from soupsavvy.models import BaseModel, Suppress\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = (\n",
    "        ClassSelector(\"price\") | Text() | Suppress(Operation(int), category=TypeError)\n",
    "    )\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">hundred</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "\n",
    "try:\n",
    "    Book.find(soup)\n",
    "except FieldExtractionException as e:\n",
    "    print(e.__cause__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all fields are nullable, meaning that if a field selector returns `None`, the corresponding field in the model instance is set to `None`. However, this behavior can be modified using the `Required` field wrapper, which raises a `FieldExtractionException` when a field selector returns `None`. This ensures that the specified field must be present in the model instance. Note that, similarly to `Default`, all errors must be explicitly handled, as the `Required` selector will propagate any exceptions that occur during extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.exceptions import FieldExtractionException\n",
    "from soupsavvy.models import BaseModel, Required, SkipNone\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = Required(ClassSelector(\"price\") | SkipNone(Text() | Operation(int)))\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "\n",
    "try:\n",
    "    Book.find(soup)\n",
    "except FieldExtractionException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, only the first element matching a field selector is used for extraction. If a different result is desired, it can be specified with the appropriate selector. For instance, the `soupsavvy.selectors.nth` selectors can be utilized to match the nth element that meets the selector criteria. In the example provided, the `NthLastOfSelector` is used to find the last element with the class `price` within the scope element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "from soupsavvy.selectors.nth import NthLastOfSelector\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = NthLastOfSelector(ClassSelector(\"price\"), nth=\"1\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"price\"><s>100</s></p>\n",
    "        <p class=\"price\"><s>80</s></p>\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">60</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we expect multiple elements to be found within the scope, the `All` field wrapper can be used. This wrapper extracts all elements matching the field selector. In the example below, all available prices for a given book are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import All, BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = All(ClassSelector(\"price\") | Text() | Operation(int))\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\"><s>100</s></p>\n",
    "        <p class=\"price\"><s>80</s></p>\n",
    "        <p class=\"price\">60</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an extracted field requires further transformation, the `__post_init__` method can be defined in the model class to handle these cases during the post-initialization step. This method functions similarly to the `__post_init__` in Python's `dataclass`. For instance, in the example below, the `price` is set to the minimum of all prices for the specific book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import All, BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = All(ClassSelector(\"price\") | Text() | Operation(int))\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.price = min(self.price)  # type: ignore\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\"><s>100</s></p>\n",
    "        <p class=\"price\"><s>80</s></p>\n",
    "        <p class=\"price\">60</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__post_init__` method can also be utilized to replace certain operations or perform more complex transformations that depend on other extracted fields. Additionally, new attributes can be set within this method, allowing for enhanced customization and flexibility in the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Text\n",
    "from soupsavvy.selectors.css import LastOfType\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text()\n",
    "    author = (LastOfType() & TypeSelector(\"p\")) | Text()\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.price = int(str(self.price).strip(\"$\"))\n",
    "        self.title = str(self.title).upper()\n",
    "        self.affordable = (self.price < 100) or (self.author == \"George Orwell\")\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100$</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "result = Book.find(soup)\n",
    "print(result)\n",
    "print(f\"Is affordable: {result.affordable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, any model class can serve as a field selector. In the example below, the `Author` model is utilized to extract author information from the `author` element within the scope. The `Author` model class is assigned as an attribute of the `Book` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, PatternSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "from soupsavvy.selectors.css import FirstChild\n",
    "\n",
    "\n",
    "class Author(BaseModel):\n",
    "    __scope__ = ClassSelector(\"author\")\n",
    "\n",
    "    birth = (\n",
    "        PatternSelector(re.compile(r\"\\d{4}-\\d{2}-\\d{2}\"))\n",
    "        | Text()\n",
    "        | Operation(lambda x: datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "    )\n",
    "    name = FirstChild() | Text()\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    author = Author\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <div class=\"author\">\n",
    "            <p>George Orwell</p>\n",
    "            <p>Great author</p>\n",
    "            <p>1903-06-25</p>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of inheritance, fields are inherited by default, which is the expected behavior. New fields can be added to extend the parent model. For example, the `eBook` model inherits from the `Book` model and adds two additional fields: `link` and `duration`. It also overrides the `__scope__`, although this is not mandatory since special fields are inherited from the parent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, PatternSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Href, Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "class eBook(Book):\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"ebook\")\n",
    "\n",
    "    link = Href()\n",
    "    duration = PatternSelector(re.compile(r\"\\d{1,2}:\\d{2}\")) | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"ebook\" href=\"www.ebook.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">50</p>\n",
    "        <p>George Orwell</p>\n",
    "        <p>2:30</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "eBook.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This default inheritance behavior can be disabled by setting `inherit_fields` to `False` in the model class. In this case, only the fields defined in the subclass will be used. For instance, in the example below, the `eBook` model does not inherit fields from the `Book` model, so only the `link` and `duration` fields are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, PatternSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Href, Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "class eBook(Book):\n",
    "    __inherit_fields__ = False\n",
    "\n",
    "    link = Href()\n",
    "    duration = PatternSelector(re.compile(r\"\\d{1,2}:\\d{2}\")) | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"ebook\" href=\"www.ebook.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">50</p>\n",
    "        <p>George Orwell</p>\n",
    "        <p>2:30</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "eBook.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is generally recommended to use the most specific scope selector possible to avoid matching elements that are unrelated to the model. This ensures that the scope selector targets only those elements expected to contain the model instance. You can used `HasSelector` to match elements that contain the elements used for extracting fields, further refining your selection criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, HasSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "PRICE_SELECTOR = ClassSelector(\"price\")\n",
    "TITLE_SELECTOR = ClassSelector(\"title\")\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = (\n",
    "        ClassSelector(\"book\")\n",
    "        & HasSelector(PRICE_SELECTOR)\n",
    "        & HasSelector(TITLE_SELECTOR)\n",
    "    )\n",
    "\n",
    "    title = TITLE_SELECTOR | Text()\n",
    "    price = PRICE_SELECTOR | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\">Unavailable</div>\n",
    "    <div class=\"book\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p>George Orwell</p>\n",
    "        <p>4:30</p>\n",
    "    </div>\n",
    "    <div class=\"book\">\n",
    "        <p class=\"price\">50</p>\n",
    "        <p>Lois Lowry</p>\n",
    "        <p>3:30</p>\n",
    "    </div>\n",
    "    <div class=\"book\">\n",
    "        <p class=\"title\">Brave New World</p>\n",
    "        <p class=\"price\">50</p>\n",
    "        <p>Aldous Huxley</p>\n",
    "        <p>2:30</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a sub-model shares the same scope as its parent model, you can use the `SelfSelector` to utilize the provided tag as the scope without searching for it. For example, in the `Author` model, the scope is inherited directly from the parent model. Alternatively, the scope of a sub-model can be defined outside of the base model's scope, parent element can be used as scope with `Parent` selector, or any specific ancestor that match selector with `Anchor << selector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, SelfSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Href, Parent, Text\n",
    "\n",
    "\n",
    "class Author(BaseModel):\n",
    "    __scope__ = SelfSelector()\n",
    "\n",
    "    name = ClassSelector(\"author\") | Text()\n",
    "\n",
    "\n",
    "class eBook(BaseModel):\n",
    "    __scope__ = Parent()\n",
    "\n",
    "    link = ClassSelector(\"ebook\") | Href()\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    author = Author\n",
    "    ebook = eBook\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div>\n",
    "        <a class=\"ebook\" href=\"www.ebook.com\"></a>\n",
    "        <div class=\"book\" href=\"www.book.com\">\n",
    "            <p class=\"title\">Animal Farm</p>\n",
    "            <p class=\"author\">George Orwell</p>\n",
    "            <p>Great author</p>\n",
    "            <p>1903-06-25</p>\n",
    "        </div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_all` method operates similarly to the `find` method, first identifying the scope element before extracting all fields from it. It returns a list of model instances for all elements that match the scope selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "from soupsavvy.selectors.css import LastOfType\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "    author = (LastOfType() & TypeSelector(\"p\")) | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"ebook\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "    <div class=\"book\">\n",
    "        <p class=\"title\">Brave New World</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>Aldous Huxley</p>\n",
    "    </div>\n",
    "    <div class=\"book\">\n",
    "        <p class=\"title\">The Giver</p>\n",
    "        <p class=\"price\">80</p>\n",
    "        <p>Lois Lowry</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find_all(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any errors encountered during extraction are propagated; if the extraction of any model fails, `find_all` method raises `FieldExtractionException`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "from soupsavvy.selectors.css import LastOfType\n",
    "from soupsavvy.exceptions import FieldExtractionException\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "    author = (LastOfType() & TypeSelector(\"p\")) | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\">\n",
    "        <p class=\"title\">Brave New World</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>Al\n",
    "    </div>\n",
    "    <div class=\"book\">\n",
    "        <p class=\"title\">The Giver</p>\n",
    "        <p>Lois Lowry</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "\n",
    "try:\n",
    "    Book.find_all(soup)\n",
    "except FieldExtractionException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no scope elements are found, the `find_all` method simply returns an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "from soupsavvy.selectors.css import LastOfType\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "    author = (LastOfType() & TypeSelector(\"p\")) | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"ebook\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "    <p class=\"title\">Animal Farm</p>\n",
    "    <p class=\"price\">100</p>\n",
    "    <p>George Orwell</p>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find_all(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recursive option is applicable exclusively to scope searches. When set to `True`, the model's scope is searched throughout all descendants of the specified tag; if set to `False`, only direct children are considered. Once the scope is identified, field selectors always perform searches in recursive mode, regardless of the `recursive` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "from soupsavvy.selectors.css import LastOfType\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "    author = (LastOfType() & TypeSelector(\"p\")) | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <span>\n",
    "            <p class=\"title\">Animal Farm</p>\n",
    "            <p class=\"price\">100</p>\n",
    "            <span class=\"author\">\n",
    "                <p>George Orwell</p>\n",
    "            </span>\n",
    "        </span>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"html.parser\")\n",
    "Book.find(soup, recursive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify this behavior and restrict field element searches to only the children of the scope element, a relative selector can be used, best created with `Anchor`. Using `Anchor > selector` limits the search to direct child elements. For example, only `price` elements that are immediate children of the `book` element will be matched. To find out more about `Anchor`, see [docs](https://soupsavvy.readthedocs.io/en/stable/demos/combining.html#anchor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import Anchor, ClassSelector, TypeSelector\n",
    "from soupsavvy.models import All, BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = All((Anchor > ClassSelector(\"price\")) | Text() | Operation(int))\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <span>\n",
    "            <p class=\"title\">Animal Farm</p>\n",
    "            <p class=\"price\">100</p>\n",
    "            <p class=\"price\">50</p>\n",
    "            <span class=\"author\">\n",
    "                <p>George Orwell</p>\n",
    "            </span>\n",
    "        </span>\n",
    "        <p class=\"price\">200</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"html.parser\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the non-recursive option, the scope is searched solely within the children of the element passed to the `find` methods. In the example below, the scope element is only found if it is a `span`. If `body` is passed instead, and it does not contain any `div` elements with class `book`, the scope will not be located, resulting in the model being `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "from soupsavvy.selectors.css import LastOfType\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "    author = (LastOfType() & TypeSelector(\"p\")) | Text()\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <span>\n",
    "        <div class=\"book\" href=\"www.book.com\">\n",
    "            <p class=\"title\">Animal Farm</p>\n",
    "            <p class=\"price\">100</p>\n",
    "            <p>George Orwell</p>\n",
    "        </div>\n",
    "    </span>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "result = Book.find(soup.body, recursive=False)  # type: ignore\n",
    "assert result is None\n",
    "\n",
    "Book.find(soup.span, recursive=False)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who prefer clean and consistent typing, `typing.cast` can be used to provide type checkers with hints regarding the types of instance fields. By default, it anticipates the same type as the type of field selector. In the example below, `typing.cast` is used to indicate to the type checker that the `title` attribute is of type `str`, while the `price` attribute can be of type `int` or `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast, Optional\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel, SkipNone\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = cast(str, ClassSelector(\"title\") | Text())\n",
    "    price = cast(\n",
    "        Optional[int], ClassSelector(\"price\") | SkipNone(Text() | Operation(int))\n",
    "    )\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "Book.find(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can migrate an instance of a model to another model using `migrate` method. This method takes another class as an argument and initializes it with the field values from the current model instance. It's particularly useful for migrating data to `pydantic` model for validation or to an `SQLAlchemy` model for database operations. The fields in both models must match for migration to work seamlessly. Additionally, you can pass extra parameters as keyword arguments, which will be forwarded to the target model's constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pydantic\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class PydanticBook(pydantic.BaseModel):\n",
    "    title: str\n",
    "    price: int\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "book = Book.find(soup)\n",
    "\n",
    "book.migrate(PydanticBook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Migration to `pydantic` model raises `ValidationError` if validation fails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pydantic\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class PydanticBook(pydantic.BaseModel):\n",
    "    title: str\n",
    "    price: str\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "book = Book.find(soup)\n",
    "\n",
    "try:\n",
    "    book.migrate(PydanticBook)\n",
    "except pydantic.ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy.orm import DeclarativeBase\n",
    "from bs4 import BeautifulSoup\n",
    "import pydantic\n",
    "from soupsavvy import ClassSelector, TypeSelector\n",
    "from soupsavvy.models import BaseModel\n",
    "from soupsavvy.operations import Operation, Text\n",
    "\n",
    "\n",
    "class Base(DeclarativeBase): ...\n",
    "\n",
    "\n",
    "class SABook(Base):\n",
    "    \"\"\"Mock model for testing migration to SQLAlchemy model.\"\"\"\n",
    "\n",
    "    __tablename__ = \"book\"\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    title = Column(String, nullable=True)\n",
    "    price = Column(Integer, nullable=True)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<SABook(title={self.title}, price={self.price})>\"\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "\n",
    "    __scope__ = TypeSelector(\"div\") & ClassSelector(\"book\")\n",
    "\n",
    "    title = ClassSelector(\"title\") | Text()\n",
    "    price = ClassSelector(\"price\") | Text() | Operation(int)\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "    <div class=\"book\" href=\"www.book.com\">\n",
    "        <p class=\"title\">Animal Farm</p>\n",
    "        <p class=\"price\">100</p>\n",
    "        <p>George Orwell</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(text, features=\"lxml\")\n",
    "book = Book.find(soup)\n",
    "\n",
    "book.migrate(SABook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`soupsavvy` offers a framework for object-oriented web scraping through user-defined models.  \n",
    "This allows users to define the structure of data they wish to extract from HTML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enjoy `soupsavvy` and leave us feedback!**  \n",
    "**Happy scraping!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soupsavvy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
